{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37532bitasulabvenv4e470b62d36d4c42a607ebf3bb60b485",
   "display_name": "Python 3.7.5 32-bit ('Asulab': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([6, 7, 8, 9, 10])\n",
    "c = a + b\n",
    "d = np.arange(8)\n",
    "d.reshape(4, 2)\n",
    "np.linspace(0, 2, num=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "for iteration # 0\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.72566269]\n [0.75334452]\n [0.75836412]\n [0.78005202]]\nLoss: \n0.313573579550288\n\n\nLayer 1: \n[[0.56570494 0.61451868 0.54346212 0.56709   ]\n [0.6313528  0.65293811 0.75640461 0.70136411]\n [0.72902257 0.61625936 0.74321464 0.59861713]\n [0.77960146 0.65460282 0.88303848 0.72780618]]\n\n\nfor iteration # 100\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.46980893]\n [0.50139325]\n [0.52731077]\n [0.53243998]]\nLoss: \n0.24406414103905177\n\n\nLayer 1: \n[[0.57678847 0.62304912 0.55012231 0.56383382]\n [0.80077394 0.67087989 0.7738889  0.69855184]\n [0.81975479 0.63122741 0.76038012 0.56814275]\n [0.93061805 0.67855583 0.89880362 0.70223274]]\n\n\nfor iteration # 200\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.23884547]\n [0.6129094 ]\n [0.65815569]\n [0.51574973]]\nLoss: \n0.14743540155290347\n\n\nLayer 1: \n[[0.32155343 0.53603948 0.58996664 0.55371823]\n [0.95492295 0.54903057 0.90862345 0.87040065]\n [0.94603584 0.80441189 0.89384791 0.50836036]\n [0.99872542 0.81251669 0.98310631 0.84841778]]\n\n\nfor iteration # 300\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.07420984]\n [0.8560804 ]\n [0.85889414]\n [0.17855253]]\nLoss: \n0.019502956040823027\n\n\nLayer 1: \n[[0.20822196 0.41375559 0.63394696 0.54725574]\n [0.9780621  0.16767608 0.94610869 0.98997789]\n [0.97578599 0.97911076 0.93874297 0.1632893 ]\n [0.99985365 0.93045399 0.99360399 0.94099663]]\n\n\nfor iteration # 400\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.03980906]\n [0.91172754]\n [0.91331688]\n [0.10897353]]\nLoss: \n0.007191495285311059\n\n\nLayer 1: \n[[0.20406192 0.43356106 0.65918934 0.57759343]\n [0.98289547 0.11894929 0.95738954 0.9957967 ]\n [0.98139607 0.99122201 0.95211438 0.11590626]\n [0.99991543 0.95219362 0.99568914 0.95783112]]\n\n\nfor iteration # 500\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.02848828]\n [0.93242074]\n [0.93354415]\n [0.0833737 ]]\nLoss: \n0.004186523051985402\n\n\nLayer 1: \n[[0.20398071 0.44521872 0.67379204 0.59146787]\n [0.98488761 0.10088792 0.96267605 0.9971925 ]\n [0.98365696 0.99419245 0.95829342 0.09837268]\n [0.99993468 0.95989731 0.99652677 0.96398625]]\n\n\nfor iteration # 600\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.02276065]\n [0.94359942]\n [0.94447774]\n [0.06958305]]\nLoss: \n0.002905898752990908\n\n\nLayer 1: \n[[0.2043932  0.45312237 0.68373593 0.59995954]\n [0.98604458 0.09090606 0.9658989  0.99781848]\n [0.9849593  0.99552413 0.96203564 0.08866039]\n [0.99994448 0.96408447 0.99699701 0.96739523]]\n\n\nfor iteration # 700\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.01924518]\n [0.95076847]\n [0.95149516]\n [0.06074839]]\nLoss: \n0.0022093018329437646\n\n\nLayer 1: \n[[0.20488135 0.45901936 0.69117584 0.60592272]\n [0.98682917 0.0843436  0.96813817 0.99817822]\n [0.98583835 0.99628712 0.96462478 0.08226402]\n [0.9999506  0.9668107  0.99730611 0.96964413]]\n\n\nfor iteration # 800\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.01683999]\n [0.95583646]\n [0.95645967]\n [0.05450589]]\nLoss: \n0.0017751637220149775\n\n\nLayer 1: \n[[0.2053591  0.46368797 0.69707424 0.61045086]\n [0.98740967 0.07959403 0.96981821 0.99841428]\n [0.98648669 0.99678606 0.96656127 0.07762892]\n [0.99995486 0.96877062 0.9975286  0.97127701]]\n\n\nfor iteration # 900\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.01507611]\n [0.95965077]\n [0.96019862]\n [0.04980856]]\nLoss: \n0.0014800978030824732\n\n\nLayer 1: \n[[0.20580639 0.46753378 0.70193594 0.61406642]\n [0.98786373 0.07594097 0.9711437  0.99858246]\n [0.98699262 0.99714038 0.96808537 0.07406071]\n [0.99995805 0.97027043 0.99769845 0.97253648]]\n\n\nfor iteration # 1000\n\nInput : \n[[0. 0. 1.]\n [0. 1. 1.]\n [1. 0. 1.]\n [1. 1. 1.]]\nActual Output: \n[[0.]\n [1.]\n [1.]\n [0.]]\nPredicted Output: \n[[0.01371873]\n [0.96264956]\n [0.96313989]\n [0.04611582]]\nLoss: \n0.001267148805535194\n\n\nLayer 1: \n[[0.2062203  0.47079279 0.70605621 0.61705588]\n [0.98823286 0.07301113 0.97222723 0.99870916]\n [0.98740314 0.99740654 0.96932874 0.07119702]\n [0.99996054 0.97146845 0.99783357 0.97354909]]\n\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Each row is a training example, each column is a feature  [X1, X2, X3]\n",
    "X = np.array(([0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]), dtype=float)\n",
    "y = np.array(([0], [1], [1], [0]), dtype=float)\n",
    "\n",
    "# Define useful functions\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(p):\n",
    "    return p * (1 - p)\n",
    "\n",
    "\n",
    "# Class definition\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(\n",
    "            self.input.shape[1], 4\n",
    "        )  # considering we have 4 nodes in the hidden layer\n",
    "        self.weights2 = np.random.rand(4, 1)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.layer2 = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        return self.layer2\n",
    "\n",
    "    def backprop(self):\n",
    "        d_weights2 = np.dot(\n",
    "            self.layer1.T, 2 * (self.y - self.output) * sigmoid_derivative(self.output)\n",
    "        )\n",
    "        d_weights1 = np.dot(\n",
    "            self.input.T,\n",
    "            np.dot(\n",
    "                2 * (self.y - self.output) * sigmoid_derivative(self.output),\n",
    "                self.weights2.T,\n",
    "            )\n",
    "            * sigmoid_derivative(self.layer1),\n",
    "        )\n",
    "\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.output = self.feedforward()\n",
    "        self.backprop()\n",
    "\n",
    "\n",
    "NN = NeuralNetwork(X, y)\n",
    "for i in range(1001):  # trains the NN 1,000 times\n",
    "    if i % 100 == 0:\n",
    "        print(\"for iteration # \" + str(i) + \"\\n\")\n",
    "        print(\"Input : \\n\" + str(X))\n",
    "        print(\"Actual Output: \\n\" + str(y))\n",
    "        print(\"Predicted Output: \\n\" + str(NN.feedforward()))\n",
    "        print(\n",
    "            \"Loss: \\n\" + str(np.mean(np.square(y - NN.feedforward())))\n",
    "        )  # mean sum squared loss\n",
    "        print(\"\\n\")\n",
    "        print(\"Layer 1: \\n\" + str(NN.layer1))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    NN.train(X, y)"
   ]
  }
 ]
}